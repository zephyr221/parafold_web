<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
  <title>
      About &middot; ParaFold
  </title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700,400italic|Source+Code+Pro:400,700" type="text/css">
  <link rel="stylesheet" href="./css/font-awesome.min.css" type="text/css">
  <link rel="stylesheet" href="./css/style.css" type="text/css">
  <link rel="shortcut icon"  type="image/x-icon" href="/assets/images/favicon.ico">
</head>

<body>
  <nav class="nav-main">
    <ul>
      <li class="logo"><a class="hvr-ripple-out" href="../index.html">P</a></li>
      <li><a class="hvr-pop button" href="../about/">About</a></li>
      <li><a href="../docs/quick-start/">Quick-Start</a></li>
      <li><a class="hvr-pop button" href="https://github.com/Zuricho/ParallelFold">GitHub</a></li>
      <li><a class="hvr-pop button" href="./">Wiki</a></li>
      <li><a class="hvr-pop button" href="../team">Our Team</a></li>
    </ul>
  </nav>

<div class="container content">
<main>
<article class="page">
  <h1 class="page-title">AlphaFold Wiki</h1>
  <p class="message">
  Hey there! This page lists a collection of useful links of AlphaFold, as well as HPC centers and GitHub issues.
</p>

<ul>
    <li><a href="#link" >Useful Links</a></li>
    <li><a href="#hpc" >HPC centers</a></li>
    <li><a href="#issue" >GitHub Issues</a></li>
    <li><a href="#video" >Video</a></li>
</ul>

          <div id="link"><h2 id="docs" class="archive__subtitle">Useful Links</h2></div>
    
          <table>
            <thead>
              <tr>
                <th>Site</th>
                <th>Introduction</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td><a href="https://github.com/deepmind/alphafold/">DeepMind AlphaFold Github</a></td>
                <td>official site</td>
              </tr>
              <tr>
                <td><a href="https://colab.research.google.com/github/deepmind/alphafold/blob/main/notebooks/AlphaFold.ipynb">DeepMind AlphaFold colab </a></td>
                <td>official colab</td>
              </tr>
              <tr>
                <td><a href="https://colab.research.google.com/github/sokrypton/ColabFold/blob/main/beta/AlphaFold2_advanced.ipynb">ColabFold colab</a></td>
                <td>by Sergey Ovchinnikov, Milot Mirdita and Martin Steinegger</td>
              </tr>
              <tr>
                <td><a href="https://www.getmoonbear.com/">MoonBear</a></td>
                <td>Use AlphaFold 2 in your browser</td>
              </tr>
              <tr>
                <td><a href="https://alphafold.ebi.ac.uk/">AlphaFold Protein Structure Database</a></td>
                <td>by DeepMind and EMBL-EBI</td>
              </tr>
              <tr>
                <td><a href="https://www.af2anatomia.jp/">AlphaFold2 dismantling new book</a></td>
                <td>by Yoshitaka Moriwak</td>
              </tr>
              <tr>
                <td><a href="https://github.com/normandavey/AlphaFold2-IDR-complex-prediction/blob/main/README.md">AlphaFold2 IDR complex prediction</a></td>
                <td>by Balint Meszaros</td>
              </tr>
            </tbody>
          </table> 

          <div id="hpc"><h2 id="docs" class="archive__subtitle">HPC centers</h2></div>
    
          <table>
            <thead>
              <tr>
                <th>HPC Centers</th>
                <th>Clusters</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td><a href="https://docs.hpc.sjtu.edu.cn/app/alphafold2.html">Shanghai Jiao Tong University</a></td>
                <td>AlphaFold2 on π2.0</td>
              </tr>
              <tr>
                <td><a href="https://hpc.nih.gov/apps/alphafold2.html">NIH </a></td>
                <td>AlphaFold2 on Biowulf</td>
              </tr>
              <tr>
                <td><a href="https://wiki.unil.ch/ci/books/high-performance-computing-hpc/page/alphafold">University of Lausanne </a></td>
                <td>AlphaFold2 on DCSR</td>
              </tr>
              <tr>
                <td><a href="https://sbgrid.org//wiki/examples/alphafold2">SBGrid </a></td>
                <td>AlphaFold2 in Harvard Medical School</td>
              </tr>
              <tr>
                <td><a href="https://confluence.desy.de/display/MXW/alphafold">Deutsches Elektronen-Synchrotron DESY</a></td>
                <td>AlphaFold2 on Maxwell</td>
              </tr>
              <tr>
                <td><a href="https://helpdesk.t3.gsic.titech.ac.jp/manuals/handbook.en/freesoft/#alphafold">Tokyo Institute of Technologya </a></td>
                <td>AlphaFold2 on TSUBAME3.0</td>
              </tr>
              <tr>
                <td><a href="https://help.rc.ufl.edu/doc/AlphaFold">University of Florida </a></td>
                <td>AlphaFold2 on HiPerGator</td>
              </tr>
              <tr>
                <td><a href="https://www.rc.virginia.edu/userinfo/rivanna/software/alphafold/">University of Virginia </a></td>
                <td>AlphaFold2 on Rivanna</td>
              </tr>
              <tr>
                <td><a href="https://ccportal.ims.ac.jp/en/node/2946">RCCS Okazaki National Institute</a></td>
                <td>AlphaFold2 on cclx</td>
              </tr>
              <tr>
                <td><a href="https://wiki.metacentrum.cz/wiki/AlphaFold">Czech National Grid Infrastructure </a></td>
                <td>AlphaFold2 on MetaCentrum</td>
              </tr>
              <tr>
                <td><a href="https://www.scl.kyoto-u.ac.jp/Appli/alphafold2.html">Kyoto University</a></td>
                <td>AlphaFold2 on SCL</td>
              </tr>
              <tr>
                <td><a href="https://biohpc.cornell.edu/lab/userguide.aspx?a=software&i=853#c">Cornell University</a></td>
                <td>AlphaFold2 on BioHPC Cloud</td>
              </tr>
              <tr>
                <td><a href="https://portal.tacc.utexas.edu/software/alphafold;jsessionid=8371C8DA73DC33BF3F787304BA6B617E">The University of Texas at Austin </a></td>
                <td>AlphaFold2 on TACC</td>
              </tr>
              <tr>
                <td><a href="https://wiki.gacrc.uga.edu/wiki/AlphaFold-Sapelo2">Georgia Advanced Computing Resource Centery</a></td>
                <td>AlphaFold2 on Sapelo2</td>
              </tr>
              <tr>
                <td><a href="https://kb.northwestern.edu/page.php?id=112835">Northwestern University</a></td>
                <td>AlphaFold2 on Quest</td>
              </tr>

            </tbody>
          </table> 
          
          <div id="issue"><h2 id="docs" class="archive__subtitle">GitHub Issues</h2></div>

          <p><a href="https://github.com/deepmind/alphafold/issues/5">Issue 5: Database disk type</a></p>
          <div class="message">
            (<a href="https://github.com/Augustin-Zidek">Augustin-Zidek</a>) The genetic search tools are very IO intensive, hence having an SSD helps.<br><br>
            For more details see e.g. the HH Suite wiki that discusses HHBlits performance: <a href="https://github.com/soedinglab/hh-suite/wiki#running-hhblits-efficiently-on-a-computer-cluster">https://github.com/soedinglab/hh-suite/wiki#running-hhblits-efficiently-on-a-computer-cluster</a>
          </div>

          <p><a href="https://github.com/deepmind/alphafold/issues/6">Issue 6: How long does it take on T1050 (779 residues)</a></p>
          <div class="message">
            (<a href="https://github.com/Augustin-Zidek">Augustin-Zidek</a>) This is hard to answer without more context, especially without knowing the speed of your CPU and your hard drive (whether it is an SSD or an HDD).<br><br>
            But in general, you can expect the time to grow with the length of the protein and the MSA search taking up to a few hours with a slow disk / CPU.<br><br>
            For the actual folding (i.e. running the AlphaFold model), the disk speed doesn't matter anymore, what matters is whether you are using a GPU and its performance.
          </div>

          <p><a href="https://github.com/deepmind/alphafold/issues/9">Issue 9: AlphaFold's speed</a></p>
          <div class="message">
            (<a href="https://github.com/tfgg">tfgg</a>) If you read the Nature paper, you'll see that AlphaFold 2 is more accurate, and the GPU times are in fact very fast: 0.6 minutes at 256 residues, 1.1 minutes at 384 residues, and 2.1 hours at 2,500 residues. These appear to be comparable to or faster than RoseTTAFold.
          </div>
          
          <p><a href="https://github.com/deepmind/alphafold/issues/12">Issue 12: GPU required?</a></p>
          <div class="message">
            (<a href="https://github.com/tfgg">tfgg</a>) You can run without a GPU (with the --use_gpu=False flag) but it'll be much slower.<br><br>

            (<a href="https://github.com/tfgg">tfgg</a>) You can run outside Docker without GPU by setting CUDA_VISIBLE_DEVICES to be empty (0 will correspond to the first GPU). If your machine doesn't have a GPU, this won't be necessary and it will run on CPU.<br><br>

            (<a href="https://github.com/huhlim">huhlim</a>) For the timing using CPU, it took more than predictions using GPUs. For a ~140 residue protein, it took ~25 minutes x 5 models for model buildings + ~25 minutes for the input feature generation. I have two Intel Xeon Silver 4214 @ 2.2GHz (24 threads for each) on a node. I have no idea how many threads were used for the inference.
          </div>

          <p><a href="https://github.com/deepmind/alphafold/issues/20">Issue 20: jaxlib version</a></p>
          <div class="message">
            (<a href="https://github.com/tfgg">tfgg</a>) We require version of 0.1.69 jaxlib to be able to use CUDA unified memory for running long sequences. If you don't need this you can probably run with 0.1.68, but that might be related to the illegal address error that you see. 
          </div>

          <p><a href="https://github.com/deepmind/alphafold/issues/53">Issue 53: GDT and lDDT Scores</a></p>
          <div class="message">
            (<a href="https://github.com/abridgland">abridgland</a>) There are a number of external tools available for computing these metrics. For GDT consider using LGA <a href="http://proteinmodel.org/AS2TS/LGA/lga.html">(http://proteinmodel.org/AS2TS/LGA/lga.html)</a> and for lDDT consider the SWISS-MODEL server <a href="https://swissmodel.expasy.org/lddt">(https://swissmodel.expasy.org/lddt)</a>. These tools are reference implementations for their respective metrics. Please note that the lDDT scores will be computed on all atoms, not just C-alpha atoms. When we use the latter in our paper it is referred to as lDDT-Ca. 
          </div>

          <p><a href="https://github.com/deepmind/alphafold/issues/61">Issue 61: predicted TM-score (pTM)</a></p>
          <div class="message">
            (<a href="https://github.com/abridgland">abridgland</a>) The *_ptm models were fine-tuned from the non-pTM models (see section 1.9.7 in the supplementary information of our paper). This is why the outputs from these models do not match exactly.<br><br>

            We recommend running the non-pTM models for structure prediction because these were used in CASP14 and have been the most thoroughly validated. We think that the pTM models are very slightly worse than the regular models (around 0.5 GDT on CASP14). You can also run one of the pTM models separately in order to get predicted aligned error. This is the protocol we use in our Colab notebook (we choose model_2_ptm for predicted aligned errors).
          </div>


          <p><a href="https://github.com/deepmind/alphafold/issues/30">Issue 30&66: Distribution over multiple GPUs</a></p>
          <div class="message">
            (<a href="https://github.com/abridgland">abridgland</a>) This code is not designed to make use of more than one GPU.<br><br>

            (<a href="https://github.com/tfgg">tfgg</a>) We don't parallelize the model itself in JAX over multiple GPUs, but we do enable unified memory which should (CUDA might be smarter) at least be able to use the host RAM as well. 
          </div>

          <p><a href="https://github.com/deepmind/alphafold/issues/74">Issue 74: Speed up prediction</a></p>
          <div class="message">
            (<a href="https://github.com/abridgland">abridgland</a>) See <a href=">https://github.com/deepmind/alphafold#inferencing-many-proteins">https://github.com/deepmind/alphafold#inferencing-many-proteins</a> for advice on how to avoid re-compilations when inferencing many proteins if that is relevant to your use case.<br><br>

            In general having more GPU memory won’t help speed up model inference unless you’re finding the GPU memory is full (i.e. you’re overflowing to host RAM). However you may be able to improve speed a bit by using a larger subbatch size: alphafold/alphafold/model/config.py Line 325<br><br>

            <code class="language-plaintext highlighter-rouge">'subbatch_size': 4,</code> <br><br>
            which trades memory for speed. Picking the right value will depend on your inputs and hardware. <br><br>
            
            Finally, depending on how much you care about accuracy, you could simply run just 1 or 2 models rather than all 5. I hope that helps!
          </div>

          <p><a href="https://github.com/deepmind/alphafold/issues/67">Issue 67: compiling the AlphaFold model</a></p>
          <div class="message">
            (<a href="https://github.com/abridgland">abridgland</a>) Model compilation is performed by the CPU. Only model inference is performed on the GPU.
          </div>

          <p><a href="https://github.com/deepmind/alphafold/issues/92">Issue 92: visualization in Colab</a></p>
          <div class="message">
            (<a href="https://github.com/ValZapod">ValZapod</a>) That is using <a href="https://github.com/molstar/molstar/issues/236">molstar/molstar#236</a>
          </div>

          <p><a href="https://github.com/deepmind/alphafold/issues/150">Issue 150: standard amino acids in FASTA sequences</a></p>
          <div class="message">
            (<a href="https://github.com/AnyaP">AnyaP</a>) AlphaFold expects an input query sequence with capitalized one-letter amino-acid types from this set:<br><br>

            <code class="language-plaintext highlighter-rouge">restypes = [ 
              'A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I', 'L', 'K', 'M', 'F', 'P', 
              'S', 'T', 'W', 'Y', 'V' 
          ]</code><br><br>
            
            Just to clarify, the input can't be a Multiple Sequence Alignment, so it shouldn't include '-' or lowercase characters. In case there are any unknown amino-acid types (represented by capital letters not from the set above), they can be converted to 'X' (see here), but this is unsupported on the Amber relaxation stage.
          </div>

          <p><a href="https://github.com/deepmind/alphafold/issues/123">Issue 123: speed up the HHblits</a></p>
          <div class="message">
            (<a href="https://github.com/andzajan">andzajan</a>) Increasing memory for the job on HPC from 32 GB to 64 GB did speed up hhblits step from 12 hours to about 2 hours for 1100 residues sequence.
            Once it has been cached it's even faster.<br><br>
            
            Some other recommedation are here: <a href="https://github.com/soedinglab/hh-suite/wiki#running-hhblits-efficiently-on-a-computer-cluster">https://github.com/soedinglab/hh-suite/wiki#running-hhblits-efficiently-on-a-computer-cluster</a><br><br>
            
            HHblits has to do a lot of I/O operations, so storing DB's on very fast SSD will help as well.
          </div>

          <p><a href="https://github.com/deepmind/alphafold/issues/149">Issue 33&149: CUDA Unified Memory</a></p>
          <div class="message">
            (<a href="https://github.com/AnyaP">AnyaP</a>) You could try increasing the value of XLA_PYTHON_CLIENT_MEM_FRACTION flag, which is set to 4.0 by default:
            alphafold/docker/run_docker.py Line 185<br><br>
            
            <code class="language-plaintext highlighter-rouge">'XLA_PYTHON_CLIENT_MEM_FRACTION': '4.0', </code> <br><br>
             
            Currently this allows allocating no more than 4*GPU_RAM in total, so you could be hitting this limit.<br><br>

            (<a href="https://github.com/tfgg">tfgg</a>) As far as I understanding the paging mechanism with unified memory will use the VRAM first, so there shouldn't be any performance hit when increasing the memory fraction..  <br><br>


            (<a href="https://github.com/ashrafgt">ashrafgt</a>) Consider fiddling with these options to be able to run the prediction with limited resources:<br>
            <a href="https://jax.readthedocs.io/en/latest/gpu_memory_allocation.html#gpu-memory-allocation">https://jax.readthedocs.io/en/latest/gpu_memory_allocation.html#gpu-memory-allocation</a>
          </div>

          <p><a href="https://github.com/deepmind/alphafold/issues/136">Issue 136: change the number of recycling</a></p>
          <div class="message">
            (<a href="https://github.com/tfgg">tfgg</a>) You can change the number of recycling iterations in AlphaFold by changing these two configuration options (to the same new number): <br><br>

            <code class="language-plaintext highlighter-rouge">config.data.common.num_recycle<br>config.model.num_recycle</code><br><br>

            this could be done, for example, in this function.<br><br>

            However, I would caution that increasing the number of recycling iterations to beyond the number used at training time ("hypercycling" as I like to call it) isn't officially tested or validated to actually provide higher levels of accuracy on an appropriate test set. Anecdotally there appears to be some successes and that unofficial Colab notebook you mention does provide the ability to do so.<br><br>

            It might be the case that pLDDT is no longer an accurate estimate of model confidence when the model is hypercycled, but you can use your own judgement and knowledge of the target to decide when to trust the prediction. Good luck!
          </div>

          <p><a href="https://github.com/deepmind/alphafold/issues/147">Issue 147: skip Amber relaxation</a></p>
          <div class="message">
            (<a href="https://github.com/tfgg">tfgg</a>) The easiest thing to do right now would be to comment out these lines: <br><br>

            <a href="https://github.com/deepmind/alphafold/blob/main/run_alphafold.py#L183-L193">https://github.com/deepmind/alphafold/blob/main/run_alphafold.py#L183-L193</a><br><br>
            
            and replace them with<br><br>
            
            <code class="language-plaintext highlighter-rouge">relaxed_pdbs[model_name] = protein.to_pdb(unrelaxed_protein)</code><br><br>
            
            I haven't tested this but this should write out the unrelaxed proteins at the end, and skip the relax step.

          </div>








          
          
          <div id="video"><h2 id="docs" class="archive__subtitle">Video</h2></div>
          <p>钟博子韬 2021-07-22 </p>
          <p><a href="https://ins.sjtu.edu.cn/seminars/1959">《Alphafold2: 如何应用AI预测蛋白质三维结构》</a></p>






</article>

</main>

<footer class="footer">
  <small>
      <span class="copyright"><i class="fa fa-copyright"></i>Copyright 2021 SJTU Network & Information Center All rights reserved. （沪交ICP备20210257）</span>
  </small>
  <div class="ftr-links">
    <a href="https://github.com/Zuricho/ParallelFold"><i class="fa fa-github-alt"></i></a>
  </div>
</footer>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-7W7PJGG03J"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-7W7PJGG03J');
</script>

</body>
</html>
